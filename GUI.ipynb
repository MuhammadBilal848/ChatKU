{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136621f-08a0-4c91-a6a9-f9539cd1d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pip3-autoremove\n",
    "!pip-autoremove torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install unsloth\n",
    "!pip install --upgrade gradio groq\n",
    "!pip install --upgrade --quiet  langchain langchain-community langchainhub\n",
    "!pip install qdrant-client>=1.1.1 sentence-transformers\n",
    "!pip install langchain langchain-community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e190a2-8f17-4f72-aa76-8ee9d2e118b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "with open('ku.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "# encoder = SentenceTransformer('thenlper/gte-large') # performed good but not able to catch outside context query\n",
    "encoder = SentenceTransformer('sentence-transformers/all-mpnet-base-v2') # works good\n",
    "\n",
    "\n",
    "def create_upload(collection_name,encoding_column):\n",
    "    client.recreate_collection(\n",
    "          collection_name=collection_name,\n",
    "          vectors_config=models.VectorParams(\n",
    "              size=encoder.get_sentence_embedding_dimension(),  # Vector size is defined by used model\n",
    "              distance=models.Distance.COSINE,\n",
    "          ), )\n",
    "\n",
    "    client.upload_points(\n",
    "          collection_name=collection_name,\n",
    "          points=[\n",
    "              models.PointStruct(\n",
    "                  id=idx, vector=encoder.encode(doc[encoding_column]).tolist(), payload={'input':doc[\"input\"],'output':doc['output']}\n",
    "              )\n",
    "              for idx, doc in enumerate(data)\n",
    "          ],\n",
    "      )\n",
    "\n",
    "def search(collection_name,query):\n",
    "    hits = client.search(\n",
    "      collection_name=collection_name,\n",
    "      query_vector=encoder.encode(query).tolist(),\n",
    "      limit=6,\n",
    "    )\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e94562-2632-42f8-94a9-8112adffc29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_upload('ins_db','instruction')\n",
    "create_upload('out_db','output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb953fe-016e-4076-8d40-a4914ec1cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"KU_Prospectus_LLM\",  \n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127471a9-ec5a-470f-9bf3-58fd6e3d7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt = \"\"\"You are a helpful chatbot for \"Karachi University\" named \"Zaroon\". You will respond only to questions regarding Karachi University's prospectus.\n",
    "\n",
    "Introduce yourself \"Assalamualikum , this is zaroor from Karachi University. What can i help you?\".\n",
    "\n",
    "ATTENTION!!! After answering correctly, stop writing.\n",
    "ATTENTION!!! DO NOT MAKE UP ANSWERS.\n",
    "ATTENTION!!! Return data as formatted as possible.\n",
    "ATTENTION!!! If user asks anything outside of university questions, say \"I don't know\".\n",
    "\n",
    "Example (from prospectus):\n",
    "Input: What undergraduate programs are offered at Karachi University?\n",
    "Output: Karachi University offers undergraduate programs in disciplines such as Arts, Science, Business Administration, and Computer Science, among others. For detailed information, please refer to the prospectus.\n",
    "\n",
    "Example (not from prospectus):\n",
    "Inout: What is the population of Karachi?\n",
    "Output: I don't know. I only respond to questions regarding Karachi University's prospectus.\n",
    "\n",
    "Here is the context from database: \\n {answers} \\n\n",
    "\n",
    "FIRST CHECK IF CONTEXT FROM DATABASE IS AT ALL RELATED TO USER QUERY IF YES THEN FORM AN ANSWER FROM CONTEXT AND YOUR INFORMATION THEN ANSWER IF NOT RELATED THEN RESPOND \"I Can't Answer This\".\n",
    "\n",
    "\n",
    "### Instruction: {ins}\n",
    "### Input: {user_input}\n",
    "### Response: {out}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9a96d-8d82-42cb-825b-c607a6dc8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import re\n",
    "\n",
    "def routing(routing_query):\n",
    "    client = Groq(api_key='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')\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"You are a genius and a helpful chatbot that helps decide whether the given query should be sent to \"University Prospectus Chatbot\" or \"Outside Domain\".                 \n",
    "                Example #1:\n",
    "                    Input: What undergraduate programs are offered at Karachi University?\n",
    "                    Output: University Prospectus Chatbot\n",
    "                Example #2:\n",
    "                    Input: What is the population of Karachi?\n",
    "                    Output: Outside Domain\n",
    "                Given the user query just tell the user if it belongs to \"University Prospectus Chatbot\" or \"Outside Domain\".\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": routing_query\n",
    "            },\n",
    "        ],\n",
    "        temperature=1,\n",
    "        max_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=False,\n",
    "        stop=None,\n",
    "    )\n",
    "    resp = completion.choices[0].message.content\n",
    "    print(\"RESP:\", resp, type(resp))\n",
    "\n",
    "    if re.search(r'Outside Domain', resp):\n",
    "        return 'Outside Domain'\n",
    "    elif re.search(r'University Prospectus Chatbot', resp):\n",
    "        return 'University Prospectus Chatbot'\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8f273-8271-4ee6-8c8a-ab4ed48d01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from threading import Thread\n",
    "from transformers import TextIteratorStreamer\n",
    "import torch\n",
    "\n",
    "def generate_response(query, input_context=\"\", max_new_tokens=1024):\n",
    "    if routing(query) == \"University Prospectus Chatbot\":\n",
    "        ans = \"\"\n",
    "        for a in search('out_db', query):\n",
    "            if a.score>0.3:\n",
    "              ans += a.payload['output'] + '\\n\\n'\n",
    "            else: \n",
    "                ans += ''\n",
    "        \n",
    "\n",
    "        prompt = my_prompt.format(answers=ans, user_input=query, ins='You are a helpful chatbot at \"Karachi University\". You introduce yourself as \"Zaroon\" and only answer questions regarding university prospectus', out='')\n",
    "        print(prompt)\n",
    "        inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "        \n",
    "        generation_kwargs = dict(\n",
    "            inputs,\n",
    "            streamer=streamer,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        \n",
    "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "        thread.start()\n",
    "        \n",
    "        generated_text = \"\"\n",
    "        for new_text in streamer:\n",
    "            generated_text += new_text\n",
    "        return generated_text\n",
    "    elif routing(query) == \"Outside Domain\":\n",
    "        return \"I am sorry, I'm not sure I was trained on this.\"\n",
    "\n",
    "def chat(query, history):\n",
    "    response = generate_response(query)\n",
    "    if response == \"I Can't Answer This\":\n",
    "        history.append((query, response))\n",
    "    else:\n",
    "        history.append((query, response.split('### Response:')[-1].replace('\\n', '').replace('\"','').replace('output:','').replace('answer:','').replace('*','').replace('Answer:','').strip()))\n",
    "\n",
    "    return history, \"\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=500)\n",
    "    msg = gr.Textbox(label=\"Enter your query\", placeholder=\"Type your message here...\")\n",
    "    submit_button = gr.Button(\"Submit\")\n",
    "    clear_button = gr.Button(\"Clear Conversation\")\n",
    "\n",
    "    submit_button.click(chat, inputs=[msg, chatbot], outputs=[chatbot, msg])\n",
    "    clear_button.click(lambda: ([], \"\"), outputs=[chatbot, msg], queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.queue().launch(share=True, inbrowser=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
